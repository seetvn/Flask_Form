{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seetvn/Flask_Form/blob/main/Copy_of_CM20315_Coursework_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coursework I -- Model hyperparameters\n",
        "\n",
        "The goal of the coursework is to modify a simple bit of numpy code that trains a network and measures the performance on a validation set for the MNist 1D dataset. \n",
        "\n",
        "In this coursework, you need to modify the **model hyperparameters** (only) to improve the performance over the current attempt.  This could mean the number of layers, the number of hidden units per layer, or the type of activation function, or any combination of the three. \n",
        "\n",
        "The only constraint is that you MUST use a fully connected network (no convolutional networks for now if you have read ahead in the book).\n",
        "\n",
        "You don't have to improve the performance much.  A few tenths of a percent is fine.  It just has to be better to get full marks.\n",
        "\n",
        "You will need to upload three things to Moodle:\n",
        "1.   The image that this notebook saves (click the folder icon on the left on colab to download it)\n",
        "2.   The lines of code you changed\n",
        "3.   The whole notebook as a .ipynb file.  You can do this on the File menu\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t9vk9Elugvmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "YrXWAH7sUWvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this once to copy the train and validation data to your CoLab environment \n",
        "# or download from my github to your local machine if you are doing this locally\n",
        "if not os.path.exists('./train_data_x.npy'):\n",
        "  !wget https://github.com/udlbook/udlbook/raw/main/practicals/train_data_x.npy\n",
        "  !wget https://github.com/udlbook/udlbook/raw/main/practicals/train_data_y.npy\n",
        "  !wget https://github.com/udlbook/udlbook/raw/main/practicals/val_data_x.npy\n",
        "  !wget https://github.com/udlbook/udlbook/raw/main/practicals/val_data_y.npy  "
      ],
      "metadata": {
        "id": "wScBGXXFVadm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data\n",
        "train_data_x = np.load('train_data_x.npy')\n",
        "train_data_y = np.load('train_data_y.npy')\n",
        "val_data_x = np.load('val_data_x.npy')\n",
        "val_data_y = np.load('val_data_y.npy')\n",
        "# Print out sizes\n",
        "print(\"Train data: %d examples (columns), each of which has %d dimensions (rows)\"%((train_data_x.shape[1],train_data_x.shape[0])))\n",
        "print(\"Validation data: %d examples (columns), each of which has %d dimensions (rows)\"%((val_data_x.shape[1],val_data_x.shape[0])))"
      ],
      "metadata": {
        "id": "8bKADvLHbiV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "489f65a7-4ed4-4592-9c1e-a99eb1406554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 4000 examples (columns), each of which has 40 dimensions (rows)\n",
            "Validation data: 2000 examples (columns), each of which has 40 dimensions (rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the network"
      ],
      "metadata": {
        "id": "_sFvRDGrl4qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# There are 40 input dimensions and 10 output dimensions for this data\n",
        "# The inputs correspond to the 40 offsets in the MNIST1D template.\n",
        "D_i = 40\n",
        "# The outputs correspond to the 10 digits\n",
        "D_o = 10\n",
        "\n",
        "# Number of hidden units in layers 1 and 2\n",
        "D_1 = 200\n",
        "D_2 = 200\n",
        "D_3=200\n",
        "D_4=200\n",
        "\n",
        "# create model with two hidden layers\n",
        "model = nn.Sequential(\n",
        "nn.Linear(D_i, D_1),\n",
        "nn.ReLU(),\n",
        "nn.Linear(D_1, D_2),\n",
        "nn.ReLU(),\n",
        "nn.Linear(D_2, D_3),\n",
        "nn.ReLU(),\n",
        "nn.Linear(D_3,D_4),\n",
        "nn.ReLU(),\n",
        "nn.Linear(D_4,D_o))"
      ],
      "metadata": {
        "id": "FslroPJJffrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# He initialization of weights\n",
        "def weights_init(layer_in):\n",
        "  if isinstance(layer_in, nn.Linear):\n",
        "    nn.init.kaiming_uniform_(layer_in.weight)\n",
        "    layer_in.bias.data.fill_(0.0)"
      ],
      "metadata": {
        "id": "YgLaex1pfhqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You need all this stuff to ensure that PyTorch is deterministic\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "metadata": {
        "id": "zXRmxCQNnL_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed so always get same result (do not change)\n",
        "set_seed(1)\n",
        "\n",
        "# choose cross entropy loss function (equation 5.24 in the loss notes)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "# construct SGD optimizer and initialize learning rate and momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9)\n",
        "# object that decreases learning rate by half every 10 epochs\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "# create 100 dummy data points and store in data loader class\n",
        "x_train = torch.tensor(train_data_x.transpose().astype('float32'))\n",
        "y_train = torch.tensor(train_data_y.astype('long'))\n",
        "x_val= torch.tensor(val_data_x.transpose().astype('float32'))\n",
        "y_val = torch.tensor(val_data_y.astype('long'))\n",
        "\n",
        "# load the data into a class that creates the batches\n",
        "data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=100, shuffle=True, worker_init_fn=np.random.seed(1))\n",
        "\n",
        "# Initialize model weights\n",
        "model.apply(weights_init)\n",
        "\n",
        "# loop over the dataset n_epoch times\n",
        "n_epoch = 50\n",
        "# store the loss and the % correct at each epoch\n",
        "losses_train = np.zeros((n_epoch))\n",
        "errors_train = np.zeros((n_epoch))\n",
        "losses_val = np.zeros((n_epoch))\n",
        "errors_val = np.zeros((n_epoch))\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  # loop over batches\n",
        "  for i, data in enumerate(data_loader):\n",
        "    # retrieve inputs and labels for this batch\n",
        "    x_batch, y_batch = data\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass -- calculate model output\n",
        "    pred = model(x_batch)\n",
        "    # compute the lss\n",
        "    loss = loss_function(pred, y_batch)\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    # SGD update\n",
        "    optimizer.step()\n",
        "\n",
        "  # Run whole dataset to get statistics -- normally wouldn't do this\n",
        "  pred_train = model(x_train)\n",
        "  pred_val = model(x_val)\n",
        "  _, predicted_train_class = torch.max(pred_train.data, 1)\n",
        "  _, predicted_val_class = torch.max(pred_val.data, 1)\n",
        "  errors_train[epoch] = 100 - 100 * (predicted_train_class == y_train).float().sum() / len(y_train)\n",
        "  errors_val[epoch]= 100 - 100 * (predicted_val_class == y_val).float().sum() / len(y_val)\n",
        "  losses_train[epoch] = loss_function(pred_train, y_train).item()\n",
        "  losses_val[epoch]= loss_function(pred_val, y_val).item()\n",
        "  print(f'Epoch {epoch:5d}, train loss {losses_train[epoch]:.6f}, train error {errors_train[epoch]:3.2f},  val loss {losses_val[epoch]:.6f}, percent error {errors_val[epoch]:3.2f}')\n",
        "  \n",
        "  # tell scheduler to consider updating learning rate\n",
        "  scheduler.step()\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(errors_train,'r-',label='train')\n",
        "ax.plot(errors_val,'b-',label='validation')\n",
        "ax.set_ylim(0,100); ax.set_xlim(0,n_epoch)\n",
        "ax.set_xlabel('Epoch'); ax.set_ylabel('Error')\n",
        "ax.set_title('Part I: Validation Result %3.2f'%(errors_val[-1]))\n",
        "ax.legend()\n",
        "ax.plot([0,n_epoch],[37.45, 37.45],'k:') # Original results. You should be better than this!\n",
        "plt.savefig('Coursework_I_Results.png',format='png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NYw8I_3mmX5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "484957e0-faef-419a-fb76-3e1030e3491d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch     0, train loss 1.536081, train error 60.12,  val loss 1.651674, percent error 66.10\n",
            "Epoch     1, train loss 1.222735, train error 46.30,  val loss 1.458209, percent error 57.00\n",
            "Epoch     2, train loss 0.949765, train error 33.38,  val loss 1.324991, percent error 49.25\n",
            "Epoch     3, train loss 0.755701, train error 27.05,  val loss 1.237975, percent error 46.30\n",
            "Epoch     4, train loss 0.627336, train error 23.62,  val loss 1.235443, percent error 44.80\n",
            "Epoch     5, train loss 0.476979, train error 18.12,  val loss 1.210164, percent error 42.10\n",
            "Epoch     6, train loss 0.383687, train error 13.00,  val loss 1.241652, percent error 40.50\n",
            "Epoch     7, train loss 0.302607, train error 9.88,  val loss 1.242512, percent error 39.55\n",
            "Epoch     8, train loss 0.280486, train error 10.10,  val loss 1.298706, percent error 38.95\n",
            "Epoch     9, train loss 0.177214, train error 5.62,  val loss 1.339733, percent error 37.95\n",
            "Epoch    10, train loss 0.049953, train error 0.60,  val loss 1.224023, percent error 33.50\n",
            "Epoch    11, train loss 0.023087, train error 0.18,  val loss 1.303284, percent error 33.65\n",
            "Epoch    12, train loss 0.012049, train error 0.00,  val loss 1.357009, percent error 32.75\n",
            "Epoch    13, train loss 0.008438, train error 0.00,  val loss 1.404334, percent error 33.20\n",
            "Epoch    14, train loss 0.006371, train error 0.00,  val loss 1.448562, percent error 33.10\n",
            "Epoch    15, train loss 0.005243, train error 0.00,  val loss 1.494926, percent error 32.60\n",
            "Epoch    16, train loss 0.004465, train error 0.00,  val loss 1.518196, percent error 32.90\n",
            "Epoch    17, train loss 0.003915, train error 0.00,  val loss 1.535506, percent error 32.60\n",
            "Epoch    18, train loss 0.003387, train error 0.00,  val loss 1.565511, percent error 32.45\n",
            "Epoch    19, train loss 0.003020, train error 0.00,  val loss 1.587131, percent error 32.35\n",
            "Epoch    20, train loss 0.002868, train error 0.00,  val loss 1.595669, percent error 32.40\n",
            "Epoch    21, train loss 0.002733, train error 0.00,  val loss 1.605839, percent error 32.40\n",
            "Epoch    22, train loss 0.002611, train error 0.00,  val loss 1.615511, percent error 32.50\n",
            "Epoch    23, train loss 0.002504, train error 0.00,  val loss 1.622370, percent error 32.25\n",
            "Epoch    24, train loss 0.002399, train error 0.00,  val loss 1.632291, percent error 32.45\n",
            "Epoch    25, train loss 0.002304, train error 0.00,  val loss 1.639989, percent error 32.40\n",
            "Epoch    26, train loss 0.002217, train error 0.00,  val loss 1.648358, percent error 32.35\n",
            "Epoch    27, train loss 0.002135, train error 0.00,  val loss 1.655141, percent error 32.15\n",
            "Epoch    28, train loss 0.002059, train error 0.00,  val loss 1.663320, percent error 32.40\n",
            "Epoch    29, train loss 0.001988, train error 0.00,  val loss 1.670025, percent error 32.25\n",
            "Epoch    30, train loss 0.001953, train error 0.00,  val loss 1.672857, percent error 32.35\n",
            "Epoch    31, train loss 0.001920, train error 0.00,  val loss 1.676127, percent error 32.20\n",
            "Epoch    32, train loss 0.001889, train error 0.00,  val loss 1.678939, percent error 32.25\n",
            "Epoch    33, train loss 0.001859, train error 0.00,  val loss 1.682038, percent error 32.20\n",
            "Epoch    34, train loss 0.001829, train error 0.00,  val loss 1.685648, percent error 32.25\n",
            "Epoch    35, train loss 0.001800, train error 0.00,  val loss 1.688933, percent error 32.20\n",
            "Epoch    36, train loss 0.001772, train error 0.00,  val loss 1.692080, percent error 32.35\n",
            "Epoch    37, train loss 0.001745, train error 0.00,  val loss 1.694250, percent error 32.25\n",
            "Epoch    38, train loss 0.001718, train error 0.00,  val loss 1.697703, percent error 32.35\n",
            "Epoch    39, train loss 0.001693, train error 0.00,  val loss 1.700226, percent error 32.30\n",
            "Epoch    40, train loss 0.001680, train error 0.00,  val loss 1.701671, percent error 32.30\n",
            "Epoch    41, train loss 0.001668, train error 0.00,  val loss 1.703734, percent error 32.25\n",
            "Epoch    42, train loss 0.001656, train error 0.00,  val loss 1.704701, percent error 32.35\n",
            "Epoch    43, train loss 0.001644, train error 0.00,  val loss 1.706161, percent error 32.25\n",
            "Epoch    44, train loss 0.001632, train error 0.00,  val loss 1.707888, percent error 32.25\n",
            "Epoch    45, train loss 0.001620, train error 0.00,  val loss 1.709340, percent error 32.25\n",
            "Epoch    46, train loss 0.001609, train error 0.00,  val loss 1.710284, percent error 32.35\n",
            "Epoch    47, train loss 0.001597, train error 0.00,  val loss 1.712114, percent error 32.20\n",
            "Epoch    48, train loss 0.001586, train error 0.00,  val loss 1.713285, percent error 32.35\n",
            "Epoch    49, train loss 0.001576, train error 0.00,  val loss 1.714530, percent error 32.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leave this all commented for now\n",
        "# We'll see how well you did on the test data after the coursework is submitted\n",
        "\n",
        "# if not os.path.exists('./test_data_x.npy'):\n",
        "#   !wget https://github.com/udlbook/udlbook/raw/main/practicals/test_data_x.npy\n",
        "#   !wget https://github.com/udlbook/udlbook/raw/main/practicals/test_data_y.npy\n",
        "\n",
        "\n",
        "# # I haven't given you this yet, leave commented\n",
        "# test_data_x = np.load('test_data_x.npy')\n",
        "# test_data_y = np.load('test_data_y.npy')\n",
        "# x_test = torch.tensor(test_data_x.transpose().astype('float32'))\n",
        "# y_test = torch.tensor(test_data_y.astype('long'))\n",
        "# pred_test = model(x_test)\n",
        "# _, predicted_test_class = torch.max(pred_test.data, 1)\n",
        "# errors_test = 100 - 100 * (predicted_test_class == y_test).float().sum() / len(y_test)\n",
        "# print(\"Test error = %3.3f\"%(errors_test))"
      ],
      "metadata": {
        "id": "O7nBz-R84QdJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}